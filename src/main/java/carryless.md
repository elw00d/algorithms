Теперь рассмотрим оптимизацию в виде отказа от переноса в интервальном кодере. Мы хотим принудительно уменьшать интервал
перед нормализацией так, чтобы переноса не возникало никогда. Так как заморачиваться с переносом мы больше не хотим, мы
можем использовать не 31 бит в числе, а все 32. Теперь нужно разобраться с условием, при котором надо уменьшать интервал.
Нормализация у нас, как и раньше, будет производиться сдвигом на 8 бит влево. Вот наш рабочий интервал
перед нормализацией:

0                                                                             2^32
|__|__|__|__|__|__|__|__|_ ... (всего 256 частей) ... _|__|__|__|__|__|__|__|__|

Любая такая часть при нормализации и отбрасывании старших битов (которые указывали на координаты этой части)
мапится на целый интервал [0; 2^32). Соответственно, перенос возникает, когда low и low+range-1 находятся
в разных частях:

    0                                2^24
____|_____________________++++++++++++|+++__

Мы помним, что мы можем беспрепятственно уменьшить размер интервала (немного проигрывая в степени сжатия),
поэтому нам достаточно всего лишь отслеживать такие ситуации и корректировать размер интервала так, чтобы
он не переходил в соседнюю часть. А после продолжать нормализацию, переноса уже не будет.

Однако, мы помним, что MIN_RANGE, при котором мы начинали нормализацию, равен 2^(PRECISION - 8), в случае
шиндлеровского кодера это было 2^(31-8)=2^23. Теперь же MIN_RANGE мы можем установить в 2^24. Но если
наш MIN_RANGE = 2^24, то корректировка размера интервала будет происходить часто. Из этих соображений
Дмитрий Субботин решил уменьшить значение MIN_RANGE до 2^16. Мы немного проигрываем в точности, но
зато интервал, меньший чем 2^16, имеет намного меньше шансов пересекать границу частей:

                                255*2^16
    0                              | 2^24
____|______________________________|_+|+____

Это происходит только если второй старший байт low равен 0xff, а (low&0xffff)+range-1 > 0xffff.
Если же low размещен в одной из 255 оставшихся долей (второй старший байт low от 0x00 до 0xfe), то
переноса точно не будет.

Как мы видим, при MIN_RANGE < 2^24 мы получили дополнительную оптимизацию, связанную с проверкой
low на причастность к последней доле рассматриваемой части. Значение маски, с которой нужно проверять low,
зависит от размера MIN_RANGE, и чем меньше выбранный MIN_RANGE, тем больше старших бит установлено в маске,
тем меньше будет количество принудительных уменьшений интервала, но вместе с тем и меньше точность в
вычислениях, когда range становится мал.

В совокупности выбранный MIN_RANGE = 2^16 кажется оптимальным или близким к оптимальному (хотя у меня
самые лучшие результаты получились с MIN_RANGE = 2^17) для 32-битного кодера.

Итак, первый вариант работал так:

// 24-битное число, в котором MIN_RANGE_LOWERIZE_BITS старших бит установлено в 1
// для MIN_RANGE = 2^16 - 0xff0000 (MIN_RANGE_LOWERIZE_BITS = 8), для MIN_RANGE = 2^24 - 0x000000 (MIN_RANGE_LOWERIZE_BITS = 0)
int mask = (~((1 << (24-MIN_RANGE_LOWERIZE_BITS)) - 1)) & 0xffffff;

while (compareUnsigned(range, MIN_RANGE) <= 0){
    if ( (low & mask) == mask &&
            compareUnsigned(range + (low & (MIN_RANGE - 1) - 1), MIN_RANGE) >= 0 ){
        range = MIN_RANGE - (low & (MIN_RANGE - 1));
    }
    stream.write(( byte ) (0xff & (low >> (PRECISION - BITS_IN_BYTE))) );
    low <<= 8;
    range <<= 8;
}

Но Дмитрий Субботин пошёл дальше и написал через пару недель следующее:

"Hi, All!
Я тут подумал, что потери в 1% для арифметического кодера это все-таки слишком
много, и слегка его соптимизировал. Теперь он теряет всего где-то 0.05%, что
имхо уже ерунда.
Параллельно как-то сам собой установился новый рекорд на размер процедуры
Encode - всего 5 строчек. 8-)"

Новшество заключалось в следующем коде:

while ((low ^ low+range)<TOP || range<BOT && ((range= -low & BOT-1),1))
       OutTgtByte(low>>24), range<<=8, low<<=8;

В переводе на человеческий это означает:

- Если старшие байты low и low+range одинаковы (а значит, кодируемое число точно лежит в одной из 256
   частей и переноса не будет, и мы можем спокойно записать этот байт в выходной поток)
  - Сбросить старший байт low в файл и нормализовать интервал
- Иначе
  - Если range < MIN_RANGE
    - Скорректировать range так, чтобы он не давал переноса при нормализации
    - Сбросить старший байт low в файл и нормализовать интервал

В чём же заключается оптимизация ? Она заключается в том, что теперь алгоритм быстрее сбрасывает биты,
когда они перестают меняться у low и low+range-1. А значит, позволяет продолжить вычисления с большей
точностью (ведь интервал уже нормализован, хотя мы не дошли до MIN_RANGE).

Здесь стоит отметить только возможные неточности, связанные с тем, что вместо low+range мы можем
использовать low+range-1 (но видимо это оставлено специально для скорости, т.к. условие
(low ^ low+range)<TOP более строгое по сравнению с (low ^ low+range-1)<TOP). А сравнение
range < BOT мы можем сделать нестрогим: range <= BOT.

UPD: Нет, нельзя, т.к. в субботинской реализации не используется 64-битное число для хранения range.