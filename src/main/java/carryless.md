ШеннонФано
Хаффман
Арифметическое кодирование - идея
Арифметическое кодирование - целочисленная реализация
Арифметическое кодирование - FAQ
Интервальное кодирование Шиндлера
Интервальное кодирование без переноса Дмитрия Субботина
Интервальное кодирование FAQ
Динамическое сжатие Маркова как развитие идеи арифметического кодирования

Теперь рассмотрим оптимизацию в виде отказа от переноса в интервальном кодере. Мы хотим принудительно уменьшать интервал
перед нормализацией так, чтобы переноса не возникало никогда. Так как заморачиваться с переносом мы больше не хотим, мы
можем использовать не 31 бит в числе, а все 32. Теперь нужно разобраться с условием, при котором надо уменьшать интервал.
Нормализация у нас, как и раньше, будет производиться сдвигом на 8 бит влево. Вот наш рабочий интервал
перед нормализацией:

0                                                                             2^32
|__|__|__|__|__|__|__|__|_ ... (всего 256 частей) ... _|__|__|__|__|__|__|__|__|

Любая такая часть при нормализации и отбрасывании старших битов (которые указывали на координаты этой части)
мапится на целый интервал [0; 2^32). Соответственно, перенос возникает, когда low и low+range-1 находятся
в разных частях:

    0                                2^24
____|_____________________++++++++++++|+++__

Мы помним, что мы можем беспрепятственно уменьшить размер интервала (немного проигрывая в степени сжатия),
поэтому нам достаточно всего лишь отслеживать такие ситуации и корректировать размер интервала так, чтобы
он не переходил в соседнюю часть. А после продолжать нормализацию, переноса уже не будет.

Однако, мы помним, что MIN_RANGE, при котором мы начинали нормализацию, равен 2^(PRECISION - 8), в случае
шиндлеровского кодера это было 2^(31-8)=2^23. Теперь же MIN_RANGE мы можем установить в 2^24. Но если
наш MIN_RANGE = 2^24, то корректировка размера интервала будет происходить часто. Из этих соображений
Дмитрий Субботин решил уменьшить значение MIN_RANGE до 2^16. Мы немного проигрываем в точности, но
зато интервал, меньший чем 2^16, имеет намного меньше шансов пересекать границу частей:

                                255*2^16
    0                              | 2^24
____|______________________________|_+|+____

Это происходит только если второй старший байт low равен 0xff, а (low&0xffff)+range-1 > 0xffff.
Если же low размещен в одной из 255 оставшихся долей (второй старший байт low от 0x00 до 0xfe), то
переноса точно не будет.

Как мы видим, при MIN_RANGE < 2^24 мы получили дополнительную оптимизацию, связанную с проверкой
low на причастность к последней доле рассматриваемой части. Значение маски, с которой нужно проверять low,
зависит от размера MIN_RANGE, и чем меньше выбранный MIN_RANGE, тем больше старших бит установлено в маске,
тем меньше будет количество принудительных уменьшений интервала, но вместе с тем и меньше точность в
вычислениях, когда range становится мал.

В совокупности выбранный MIN_RANGE = 2^16 кажется оптимальным или близким к оптимальному (хотя у меня
самые лучшие результаты получились с MIN_RANGE = 2^17) для 32-битного кодера.

Итак, первый вариант работал так:

// 24-битное число, в котором MIN_RANGE_LOWERIZE_BITS старших бит установлено в 1
// для MIN_RANGE = 2^16 - 0xff0000 (MIN_RANGE_LOWERIZE_BITS = 8), для MIN_RANGE = 2^24 - 0x000000 (MIN_RANGE_LOWERIZE_BITS = 0)
int mask = (~((1 << (24-MIN_RANGE_LOWERIZE_BITS)) - 1)) & 0xffffff;

while (compareUnsigned(range, MIN_RANGE) <= 0){
    if ( (low & mask) == mask &&
            compareUnsigned(range + (low & (MIN_RANGE - 1) - 1), MIN_RANGE) >= 0 ){
        range = MIN_RANGE - (low & (MIN_RANGE - 1));
    }
    stream.write(( byte ) (0xff & (low >> (PRECISION - BITS_IN_BYTE))) );
    low <<= 8;
    range <<= 8;
}

Но Дмитрий Субботин пошёл дальше и написал через пару недель следующее:

"Hi, All!
Я тут подумал, что потери в 1% для арифметического кодера это все-таки слишком
много, и слегка его соптимизировал. Теперь он теряет всего где-то 0.05%, что
имхо уже ерунда.
Параллельно как-то сам собой установился новый рекорд на размер процедуры
Encode - всего 5 строчек. 8-)"

Новшество заключалось в следующем коде:

while ((low ^ low+range)<TOP || range<BOT && ((range= -low & BOT-1),1))
       OutTgtByte(low>>24), range<<=8, low<<=8;

В переводе на человеческий это означает:

- Если старшие байты low и low+range одинаковы (а значит, кодируемое число точно лежит в одной из 256
   частей и переноса не будет, и мы можем спокойно записать этот байт в выходной поток)
  - Сбросить старший байт low в файл и нормализовать интервал
- Иначе
  - Если range < MIN_RANGE
    - Скорректировать range так, чтобы он не давал переноса при нормализации
    - Сбросить старший байт low в файл и нормализовать интервал

В чём же заключается оптимизация ? Она заключается в том, что теперь алгоритм быстрее сбрасывает старшие биты в выходной файл,
когда они перестают меняться у low и low+range. Если раньше интервал всегда уменьшался до MIN_RANGE, и только потом
нормализовывался, то теперь мы выполняем нормализацию сразу же, как только можем. А это позволяет
продолжить вычисления с большей точностью (ведь интервал уже нормализован, хотя мы не дошли до MIN_RANGE).

Здесь стоит отметить только то, что вместо low+range мы могли бы использовать low+range-1, а сравнение
range < BOT сделать нестрогим: range <= BOT. Но из-за того, что range ограничен 32 битами, мы не можем на это пойти,
т.к. в противном случае range может стать равным 2^32, и это число не поместится в 32 бита. Из этих же соображений
на старте мы инициализируем range не числом 2^32, а числом 2^32 - 1. Так как мы ещё можем перейти к long для хранения
range, то мы можем выполнить эти изменения, но не проще ли в таком случае перейти сразу к 64-битной реализации ?
